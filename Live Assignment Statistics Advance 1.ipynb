{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question1: Define the z-statistic and explain its relationship to the standard normal distribution. How is the\n",
        "z-statistic used in hypothesis testing?\n",
        "\n",
        "\n",
        "Answer- The z-statistic is a measure that describes how many standard deviations a data point or sample statistic is from the mean of a population. It is calculated using the formula:\n",
        "\n",
        "[ z = \\frac{(X - \\mu)}{\\sigma} ]\n",
        "\n",
        "where:\n",
        "\n",
        "( X ) is the value or sample mean,\n",
        "( \\mu ) is the population mean,\n",
        "( \\sigma ) is the population standard deviation.\n",
        "If you're working with a sample mean, the formula becomes:\n",
        "\n",
        "[ z = \\frac{(\\bar{X} - \\mu)}{\\frac{\\sigma}{\\sqrt{n}}} ]\n",
        "\n",
        "where:\n",
        "\n",
        "( \\bar{X} ) is the sample mean,\n",
        "( n ) is the sample size.\n",
        "The z-statistic is directly related to the standard normal distribution, which is a normal distribution with a mean of 0 and a standard deviation of 1. When data is transformed into z-scores, it allows for comparison across different normal distributions by standardizing the values.\n",
        "\n",
        "In hypothesis testing, the z-statistic is used to determine whether to reject the null hypothesis. Here's how it works:\n",
        "\n",
        "Set up Hypotheses: Define the null hypothesis (( H_0 )) and the alternative hypothesis (( H_a )).\n",
        "\n",
        "Calculate the Z-Statistic: Use the relevant formula to calculate the z-statistic for your sample data.\n",
        "\n",
        "Determine the Significance Level: Decide on a significance level (( \\alpha )), commonly 0.05.\n",
        "\n",
        "Find the Critical Value(s): Determine the critical z-value(s) from the standard normal distribution that correspond to your significance level.\n",
        "\n",
        "Make a Decision:\n",
        "\n",
        "If the calculated z-statistic falls beyond the critical value(s) in the tail(s) of the distribution, reject ( H_0 ).\n",
        "If the z-statistic falls within the critical value(s), do not reject ( H_0 ).\n",
        "The z-statistic thus provides a way to assess whether observed data is significantly different from what is expected under the null hypothesis."
      ],
      "metadata": {
        "id": "NgsZXToLa99b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question2 : What is a p-value, and how is it used in hypothesis testing? What does it mean if the p-value is\n",
        "very small (e.g., 0.01)?\n",
        "\n",
        "Answer- A p-value is a statistical measure used in hypothesis testing to determine the strength of evidence against the null hypothesis. It represents the probability of obtaining a result at least as extreme as the observed data, assuming that the null hypothesis is true.\n",
        "\n",
        "Hypothesis Testing Process:\n",
        "Formulate Hypotheses:\n",
        "\n",
        "Null Hypothesis (H0): A statement of no effect or no difference.\n",
        "Alternative Hypothesis (H1): A statement indicating the presence of an effect or difference.\n",
        "Conduct the Test:\n",
        "\n",
        "Collect data and perform a statistical test to calculate the p-value.\n",
        "Interpret the P-Value:\n",
        "\n",
        "Small P-Value: Indicates strong evidence against the null hypothesis. Suggests that the observed data is unlikely under the null hypothesis.\n",
        "Large P-Value: Indicates weak evidence against the null hypothesis. Suggests that the observed data is likely under the null hypothesis.\n",
        "What Does a Very Small P-Value Mean?\n",
        "Example (p-value = 0.01):\n",
        "A p-value of 0.01 means there is a 1% probability of observing the data, or something more extreme, if the null hypothesis is true.\n",
        "It suggests strong evidence against the null hypothesis, often leading to its rejection in favor of the alternative hypothesis.\n",
        "In many fields, a threshold (alpha level) of 0.05 is commonly used. A p-value of 0.01 would be considered statistically significant, as it is below this threshold.\n",
        "Conclusion:\n",
        "A very small p-value indicates that the observed result is highly unlikely under the assumption of the null hypothesis, providing strong evidence to consider rejecting the null hypothesis in favor of the alternative."
      ],
      "metadata": {
        "id": "Bh5VLEHqbXxa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cXClS8l4bm7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question3: Compare and contrast the binomial and Bernoulli distributions.\n",
        "\n",
        " Answer- The binomial and Bernoulli distributions are closely related, but they have some key differences. Here's a comparison:\n",
        "\n",
        "Bernoulli Distribution\n",
        "Definition: Represents a single trial with two possible outcomes: success (1) or failure (0).\n",
        "Parameters:\n",
        "( p ): Probability of success.\n",
        "Support: ({0, 1}).\n",
        "Mean: ( p ).\n",
        "Variance: ( p(1-p) ).\n",
        "Use Case: Models the outcome of a single experiment or trial.\n",
        "Binomial Distribution\n",
        "Definition: Represents the number of successes in a fixed number of independent Bernoulli trials.\n",
        "Parameters:\n",
        "( n ): Number of trials.\n",
        "( p ): Probability of success in each trial.\n",
        "Support: ({0, 1, 2, \\ldots, n}).\n",
        "Mean: ( np ).\n",
        "Variance: ( np(1-p) ).\n",
        "Use Case: Models the total number of successes across multiple trials.\n",
        "Key Differences\n",
        "Scope:\n",
        "\n",
        "The Bernoulli distribution is for a single trial, while the binomial distribution is for multiple trials.\n",
        "Parameters:\n",
        "\n",
        "Bernoulli has one parameter (( p )), while binomial has two (( n ) and ( p )).\n",
        "Range:\n",
        "\n",
        "Bernoulli outcomes are binary ((0) or (1)), whereas binomial outcomes range from (0) to (n).\n",
        "Relationship\n",
        "A binomial distribution with ( n = 1 ) is equivalent to a Bernoulli distribution.\n",
        "Both distributions are foundational in probability and statistics, especially in scenarios dealing with binary outcomes."
      ],
      "metadata": {
        "id": "Zaax7eZebnce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Under what conditions is the binomial distribution used, and how does it relate to the Bernoulli\n",
        "distribution?\n",
        "\n",
        "Answer- The binomial distribution is used under the following conditions:\n",
        "\n",
        "1. **Fixed Number of Trials**: There is a set number of independent trials, denoted as \\( n \\).\n",
        "\n",
        "2. **Binary Outcomes**: Each trial has two possible outcomes, often termed \"success\" and \"failure.\"\n",
        "\n",
        "3. **Constant Probability**: The probability of success, denoted as \\( p \\), is the same for each trial.\n",
        "\n",
        "4. **Independence**: The trials are independent, meaning the outcome of one trial does not affect the others.\n",
        "\n",
        "The binomial distribution is related to the Bernoulli distribution in that:\n",
        "\n",
        "- A Bernoulli distribution is the distribution of a single trial that results in a success with probability \\( p \\) and a failure with probability \\( 1-p \\).\n",
        "\n",
        "- The binomial distribution models the number of successes in \\( n \\) independent Bernoulli trials, each with success probability \\( p \\).\n",
        "\n",
        "In essence, if you have \\( n \\) Bernoulli trials, the sum of these trials follows a binomial distribution \\( \\text{Binomial}(n, p) \\)."
      ],
      "metadata": {
        "id": "ebi24yjacB0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question5: What are the key properties of the Poisson distribution, and when is it appropriate to use this\n",
        "distribution?\n",
        "\n",
        "Answer- The Poisson distribution is a discrete probability distribution that models the number of events occurring within a fixed interval of time or space. Here are its key properties and when it is appropriate to use:\n",
        "\n",
        "### Key Properties:\n",
        "\n",
        "1. **Discrete Distribution**: It deals with discrete events.\n",
        "\n",
        "2. **Defined by a Single Parameter (\\(\\lambda\\))**:\n",
        "   - \\(\\lambda\\) is the average number of events in the interval.\n",
        "   - The mean and variance of the distribution are both equal to \\(\\lambda\\).\n",
        "\n",
        "3. **Probability Mass Function**:\n",
        "   - The probability of observing \\(k\\) events is given by:\n",
        "     \\[\n",
        "     P(X = k) = \\frac{e^{-\\lambda} \\lambda^k}{k!}\n",
        "     \\]\n",
        "   - Where \\(e\\) is the base of the natural logarithm, approximately equal to 2.71828.\n",
        "\n",
        "4. **Memoryless Property**:\n",
        "   - The number of events in disjoint intervals are independent.\n",
        "\n",
        "### When to Use the Poisson Distribution:\n",
        "\n",
        "1. **Rare Events**:\n",
        "   - Appropriate for modeling rare events over a large number of trials or a large population.\n",
        "\n",
        "2. **Fixed Interval**:\n",
        "   - Events are counted in a fixed interval of time, space, volume, or area.\n",
        "\n",
        "3. **Independent Events**:\n",
        "   - Events occur independently within the interval.\n",
        "\n",
        "4. **Constant Average Rate**:\n",
        "   - The average rate (\\(\\lambda\\)) of occurrence is constant over the interval.\n",
        "\n",
        "5. **Small Probability of Occurrence**:\n",
        "   - Each individual event has a small probability of occurring.\n",
        "\n",
        "### Examples:\n",
        "\n",
        "- Modeling the number of phone calls received by a call center per hour.\n",
        "- Counting the number of decay events per unit time from a radioactive source.\n",
        "- Determining the number of emails received per day.\n",
        "\n",
        "By understanding these properties and conditions, you can effectively determine when to use the Poisson distribution for modeling count data."
      ],
      "metadata": {
        "id": "TeXWClzMcQ9D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zl1DrugBcVgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question6: Define the terms \"probability distribution\" and \"probability density function\" (PDF). How does a\n",
        "PDF differ from a probability mass function (PMF)?\n",
        "\n",
        "Answer- ### Probability Distribution\n",
        "\n",
        "A probability distribution is a mathematical function that provides the probabilities of occurrence of different possible outcomes in an experiment. It characterizes the likelihood of different outcomes and can be discrete or continuous.\n",
        "\n",
        "### Probability Density Function (PDF)\n",
        "\n",
        "A probability density function (PDF) is associated with continuous random variables. It describes the likelihood of a random variable taking on a particular value. The PDF is such that the area under the curve over an interval represents the probability of the variable falling within that interval.\n",
        "\n",
        "Key points about PDF:\n",
        "- The value of the PDF at any point is not the probability itself but a density.\n",
        "- The total area under the PDF curve equals 1.\n",
        "- Probabilities are found by integrating the PDF over a range of values.\n",
        "\n",
        "### Probability Mass Function (PMF)\n",
        "\n",
        "A probability mass function (PMF) is associated with discrete random variables. It gives the probability that a discrete random variable is exactly equal to some value.\n",
        "\n",
        "Key points about PMF:\n",
        "- The PMF assigns probabilities to discrete outcomes.\n",
        "- The sum of all probabilities in the PMF equals 1.\n",
        "- Probabilities are directly given by the PMF for each possible outcome.\n",
        "\n",
        "### Differences between PDF and PMF\n",
        "\n",
        "1. **Nature of Random Variable**:\n",
        "   - PMF is used for discrete random variables.\n",
        "   - PDF is used for continuous random variables.\n",
        "\n",
        "2. **Probability Calculation**:\n",
        "   - PMF gives the probability of the random variable being exactly equal to a specific value.\n",
        "   - PDF gives the density; probabilities are calculated by integrating over an interval.\n",
        "\n",
        "3. **Values**:\n",
        "   - PMF values are actual probabilities (between 0 and 1).\n",
        "   - PDF values are densities and can be greater than 1; it's the area under the curve that represents probability.\n",
        "\n",
        "Understanding these distinctions is crucial for correctly analyzing and interpreting data in probabilistic models.\n"
      ],
      "metadata": {
        "id": "sD25EfAfckUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question7: Explain the Central Limit Theorem (CLT) with example.\n",
        "\n",
        "Answer- ### Central Limit Theorem (CLT)\n",
        "\n",
        "The Central Limit Theorem is a fundamental concept in statistics that states that the distribution of the sample mean of a large number of independent, identically distributed variables approaches a normal distribution, regardless of the original distribution of the population. This is true as long as the sample size is sufficiently large.\n",
        "\n",
        "### Key Points of CLT:\n",
        "\n",
        "1. **Sample Size**: The theorem applies as the sample size (\\(n\\)) becomes large, typically \\(n > 30\\) is considered sufficient.\n",
        "\n",
        "2. **Independence**: The sampled observations must be independent.\n",
        "\n",
        "3. **Identically Distributed**: Each observation comes from the same probability distribution.\n",
        "\n",
        "4. **Mean and Variance**:\n",
        "   - The mean of the sampling distribution (\\(\\mu_{\\bar{x}}\\)) will be equal to the mean of the population (\\(\\mu\\)).\n",
        "   - The variance of the sampling distribution (\\(\\sigma^2_{\\bar{x}}\\)) will be \\(\\sigma^2/n\\), where \\(\\sigma^2\\) is the population variance.\n",
        "\n",
        "### Example:\n",
        "\n",
        "Imagine you are rolling a fair six-sided die. The distribution of outcomes (1 through 6) is uniform, not normal.\n",
        "\n",
        "1. **Population Parameters**:\n",
        "   - Mean (\\(\\mu\\)): \\(\\frac{1+2+3+4+5+6}{6} = 3.5\\)\n",
        "   - Variance (\\(\\sigma^2\\)): Calculated as \\(\\frac{1}{6}\\sum (x_i - 3.5)^2\\)\n",
        "\n",
        "2. **Sampling**:\n",
        "   - Take samples of size \\(n = 30\\) rolls and calculate their means.\n",
        "   - Repeat this process many times to create a distribution of sample means.\n",
        "\n",
        "3. **Application of CLT**:\n",
        "   - According to the CLT, as \\(n\\) becomes large, the distribution of these sample means will approach a normal distribution.\n",
        "   - Regardless of the original uniform distribution of die rolls, the distribution of the sample means will be approximately normal with:\n",
        "     - Mean \\(\\mu_{\\bar{x}} = 3.5\\)\n",
        "     - Standard deviation \\(\\sigma_{\\bar{x}} = \\sigma/\\sqrt{n}\\)\n",
        "\n",
        "### Importance:\n",
        "\n",
        "- **Practical Use**: The CLT allows statisticians to make inferences about population parameters using sample statistics.\n",
        "- **Confidence Intervals**: It underpins the construction of confidence intervals and hypothesis testing.\n",
        "  \n",
        "The Central Limit Theorem is powerful because it enables the use of normal distribution techniques even when the underlying population distribution is not normal."
      ],
      "metadata": {
        "id": "sCtlzQ8jctyS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNNbKDcBcsy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question8: Compare z-scores and t-scores. When should you use a z-score, and when should a t-score be applied instead?\n",
        "\n",
        "Answer- ### Z-Scores\n",
        "\n",
        "A z-score is a statistical measurement that describes a value's position relative to the mean of a group of values, expressed in terms of standard deviations from the mean.\n",
        "\n",
        "**When to Use Z-Scores:**\n",
        "\n",
        "1. **Known Population Standard Deviation**: Use when the population standard deviation (\\(\\sigma\\)) is known.\n",
        "2. **Large Sample Size**: Typically appropriate for large sample sizes (\\(n > 30\\)).\n",
        "3. **Normal Distribution**: Assumes that the population from which the sample is drawn is normally distributed or approximately normal.\n",
        "\n",
        "### T-Scores\n",
        "\n",
        "A t-score is similar to a z-score but is used when the sample size is small and/or the population standard deviation is unknown. The t-score accounts for the additional uncertainty by using the sample standard deviation.\n",
        "\n",
        "**When to Use T-Scores:**\n",
        "\n",
        "1. **Unknown Population Standard Deviation**: Use when \\(\\sigma\\) is unknown and you estimate it using the sample standard deviation (\\(s\\)).\n",
        "2. **Small Sample Size**: Appropriate for smaller sample sizes (\\(n \\leq 30\\)).\n",
        "3. **T-Distribution**: Relies on the t-distribution, which is wider and has heavier tails than the normal distribution, especially for smaller sample sizes.\n",
        "\n",
        "### Key Differences:\n",
        "\n",
        "- **Distribution**: Z-scores are based on the standard normal distribution, while t-scores are based on the t-distribution.\n",
        "- **Sample Size and Variability**: T-scores account for additional variability due to small sample sizes and unknown population standard deviation.\n",
        "\n",
        "### Summary:\n",
        "\n",
        "- Use **z-scores** when the population standard deviation is known and the sample size is large.\n",
        "- Use **t-scores** when the population standard deviation is unknown or the sample size is small, making the t-distribution more suitable to handle the additional variability."
      ],
      "metadata": {
        "id": "WFS7VCouc_iX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question9: Given a sample mean of 105, a population mean of 100, a standard deviation of 15, and a sample\n",
        "size of 25, calculate the z-score and p-value. Based on a significance level of 0.05, do you reject or fail to\n",
        "reject the null hypothesis?\n",
        "\n",
        " Task: Write Python code to calculate the z-score and p-value for the given data.\n",
        "\n",
        "Objective: Apply the formula for the z-score and interpret the p-value for hypothesis testing.\n",
        "\n",
        "Answer- To calculate the z-score and p-value, we can use the following steps:\n",
        "\n",
        "### Z-Score Calculation\n",
        "The z-score is calculated using the formula:\n",
        "\n",
        "\\[\n",
        "z = \\frac{\\bar{x} - \\mu}{\\sigma / \\sqrt{n}}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\(\\bar{x}\\) = sample mean = 105\n",
        "- \\(\\mu\\) = population mean = 100\n",
        "- \\(\\sigma\\) = standard deviation = 15\n",
        "- \\(n\\) = sample size = 25\n",
        "\n",
        "### Python Code\n",
        "Let's calculate the z-score and p-value using Python.\n",
        "\n",
        "```python\n",
        "import scipy.stats as stats\n",
        "import math\n",
        "\n",
        "# Given values\n",
        "sample_mean = 105\n",
        "population_mean = 100\n",
        "standard_deviation = 15\n",
        "sample_size = 25\n",
        "\n",
        "# Calculate the z-score\n",
        "z_score = (sample_mean - population_mean) / (standard_deviation / math.sqrt(sample_size))\n",
        "\n",
        "# Calculate the p-value\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "# Output the results\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Determine whether to reject the null hypothesis\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis.\")\n",
        "```\n",
        "\n",
        "### Interpretation\n",
        "- **Z-Score**: This tells us how many standard deviations the sample mean is from the population mean.\n",
        "- **P-Value**: This is the probability of observing a sample mean as extreme as the one observed, under the null hypothesis.\n",
        "\n",
        "### Decision\n",
        "- **Significance Level (\\(\\alpha\\))**: 0.05\n",
        "- If the p-value is less than 0.05, we reject the null hypothesis.\n",
        "- If the p-value is greater than or equal to 0.05, we fail to reject the null hypothesis.\n",
        "\n",
        "By running the code, you'll be able to determine the z-score, p-value, and make an informed decision on whether to reject or fail to reject the null hypothesis."
      ],
      "metadata": {
        "id": "CsmWUFK5dJwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question10: Simulate a binomial distribution with 10 trials and a probability of success of 0.6 using Python.\n",
        "Generate 1,000 samples and plot the distribution. What is the expected mean and variance?\n",
        "\n",
        "Task: Use Python to generate the data, plot the distribution, and calculate the mean and variance.\n",
        "\n",
        "Objective: Understand the properties of a binomial distribution and verify them through simulation.\n",
        "\n",
        "Answer- To simulate a binomial distribution with 10 trials and a probability of success of 0.6, we can use Python's NumPy library. We'll generate 1,000 samples, plot the distribution, and calculate the expected mean and variance.\n",
        "\n",
        "### Python Code\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters for the binomial distribution\n",
        "n_trials = 10\n",
        "probability_of_success = 0.6\n",
        "n_samples = 1000\n",
        "\n",
        "# Generate binomial distribution samples\n",
        "samples = np.random.binomial(n_trials, probability_of_success, n_samples)\n",
        "\n",
        "# Plot the distribution\n",
        "plt.hist(samples, bins=range(n_trials + 2), density=True, edgecolor='black', alpha=0.7)\n",
        "plt.title('Binomial Distribution (n=10, p=0.6)')\n",
        "plt.xlabel('Number of Successes')\n",
        "plt.ylabel('Probability')\n",
        "plt.xticks(range(n_trials + 1))\n",
        "plt.show()\n",
        "\n",
        "# Calculate the mean and variance\n",
        "mean = np.mean(samples)\n",
        "variance = np.var(samples)\n",
        "\n",
        "# Expected mean and variance\n",
        "expected_mean = n_trials * probability_of_success\n",
        "expected_variance = n_trials * probability_of_success * (1 - probability_of_success)\n",
        "\n",
        "print(f\"Simulated Mean: {mean}\")\n",
        "print(f\"Simulated Variance: {variance}\")\n",
        "print(f\"Expected Mean: {expected_mean}\")\n",
        "print(f\"Expected Variance: {expected_variance}\")\n",
        "```\n",
        "\n",
        "### Expected Mean and Variance\n",
        "\n",
        "For a binomial distribution, the expected mean (\\(\\mu\\)) and variance (\\(\\sigma^2\\)) are given by:\n",
        "\n",
        "- **Mean**: \\(\\mu = n \\cdot p\\)\n",
        "- **Variance**: \\(\\sigma^2 = n \\cdot p \\cdot (1 - p)\\)\n",
        "\n",
        "Where:\n",
        "- \\(n\\) = number of trials = 10\n",
        "- \\(p\\) = probability of success = 0.6\n",
        "\n",
        "### Calculation\n",
        "\n",
        "- **Expected Mean**: \\(10 \\times 0.6 = 6\\)\n",
        "- **Expected Variance**: \\(10 \\times 0.6 \\times 0.4 = 2.4\\)\n",
        "\n",
        "By running the code, you can verify the properties of the binomial distribution through simulation and see how the simulated mean and variance compare to the expected values."
      ],
      "metadata": {
        "id": "SiLj7OC7dks7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hQLzE4_XdJRa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}